Initial approach:

Using requests and BeautifulSoup to scrape the content.

Problem encountered: The content is dynamically loaded by JavaScript, making this method inefficient.

Approach with Selenium:

Using Selenium to interact with the page and execute the JavaScript.

Problem encountered: Despite waiting and scrolling, the desired elements are still not found.

Debugging and adjustments:

Adding debugging to display the retrieved HTML content and verify the element structure.

Attempts with CSS selectors and XPath to target specific elements.

Persistent problems:

The elements are still not found, possibly indicating a problem with the selectors used or the dynamic loading of the content.

Final attempt with Puppeteer (Node.js):

Suggesting using Puppeteer to interact with the page and retrieve the dynamically loaded elements.

For next time, we could:

Review the CSS selectors used to ensure they correspond to the actual page elements.

Continue using Puppeteer if necessary to better handle dynamically loaded content.
